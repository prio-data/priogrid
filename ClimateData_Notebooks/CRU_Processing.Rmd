

```{r}
#install.packages("terra")     # For raster and NetCDF handling
library(terra)
library(sf)
library(dplyr)
library(ggplot2)

library(lubridate)


```

## Working from the team processes:

#### Identify the appropriate identifying fields for
- {harrisVersion4CRU2020} {priogrid}



# Function 1:

```{r}
#' Reads the CRU data
#'
#' 
#'
#' @return an object of class sf
#' @export
#'
#' @references
#' \insertRef{harrisVersion4CRU2020}{priogrid}
read_cru <- function() {
  f <- get_pgfile(source_name = "CRU Climate",
                  source_version = "v4.09",
                  id = "d9ffee47-4e83-4805-9b3f-5e0e889fd2db")

  return(f)
}
```

```{r}
f <- read_cru()
```

#### Visualize the index
```{r}
print(f)
```


```{r}
load_cru_temperature <- function(index, sources) {
  library(terra)
  library(R.utils)
  library(tools)

  # Validate index
  if (index < 1 || index > length(sources)) {
    stop(sprintf("Index %d is out of bounds. Found %d sources.", index, length(sources)))
  }

  gz_file <- sources[index]

  # Extract file components
  filename <- basename(gz_file)
  base_name <- sub("\\.dat\\.nc\\.gz$", "", filename)  # "cru_ts4.09.1981.1990.tmp"
  parent_dir <- dirname(gz_file)
  target_dir <- file.path(parent_dir, sub("\\.tmp$", "", base_name))  # remove ".tmp"
  dir.create(target_dir, showWarnings = FALSE, recursive = TRUE)

  # Define unzipped NetCDF file destination
  nc_file <- file.path(target_dir, sub("\\.gz$", "", filename))  # "cru_ts4.09.1981.1990.tmp.dat.nc"

  # Decompress if needed
  if (!file.exists(nc_file)) {
    message("üì¶ Decompressing to: ", nc_file)
    gunzip(gz_file, destname = nc_file, remove = FALSE, overwrite = TRUE)
  }

  # Load NetCDF
  temp <- rast(nc_file)
  tmp_idx <- grep("^tmp", names(temp))
  temp_only <- temp[[tmp_idx]]

  # Annotate raster
  start_year <- as.numeric(sub(".*(\\d{4})\\..*", "\\1", filename))
  dates <- seq(as.Date(sprintf("%d-01-16", start_year)), by = "month", length.out = nlyr(temp_only))
  time(temp_only) <- dates
  names(temp_only) <- paste0("tmp_", format(dates, "%Y_%m"))

  return(temp_only)
}


```

## Loads just one index:
```{r}
temperature_stack <- load_cru_temperature(1, f) 

```

### Performs a batch process:
```{r}
load_all_cru_temperature <- function(sources) {
  message("Processing ", length(sources), " CRU files...")

  temp_list <- lapply(seq_along(sources), function(i) {
    message("Loading file ", i, " of ", length(sources))
    load_cru_temperature(i, sources)
  })

  # Merge into single SpatRaster if needed
  combined <- do.call(c, temp_list)
  return(combined)
}
```

```{r}
cru_temp <- load_all_cru_temperature(f)
```

#### Generate a raster stack from the unzipped .nc files just created:
```{r}
stack_cru_temperature_from_sources <- function(sources, save_name = 'cru_stack', plot_layer = "tmp_2020_01") {
  library(terra)
  
  # 1. Derive parent directory from the first .gz path in sources
  if (length(sources) == 0) stop("‚ùå 'sources' is empty.")
  parent_dir <- dirname(sources[1])
  message("üìÅ Searching unzipped .nc files in: ", parent_dir)

  # 2. Recursively find all .nc files in subdirectories
  nc_files <- list.files(parent_dir, pattern = "\\.nc$", full.names = TRUE, recursive = TRUE)
  if (length(nc_files) == 0) stop("‚ùå No .nc files found in: ", parent_dir)

  # 3. Function to load and annotate one .nc file
  load_nc_file <- function(nc_path) {
    temp <- rast(nc_path)
    tmp_idx <- grep("^tmp", names(temp))
    temp_only <- temp[[tmp_idx]]
    
    start_year <- as.numeric(sub(".*(\\d{4})\\..*", "\\1", basename(nc_path)))
    dates <- seq(as.Date(sprintf("%d-01-16", start_year)), by = "month", length.out = nlyr(temp_only))
    
    time(temp_only) <- dates
    names(temp_only) <- paste0("tmp_", format(dates, "%Y_%m"))
    
    return(temp_only)
  }

  # 4. Load all unzipped .nc files and build the full stack
  temp_stack_list <- lapply(nc_files, load_nc_file)

  # 5. Concatenate into a single time-series raster
  cru_temp_stack <- do.call(c, temp_stack_list)
  message("‚úÖ Raster stack created with ", nlyr(cru_temp_stack), " monthly layers.")

  # 6. Optional: Save to disk
  
  save_path <- file.path(parent_dir, paste0(save_name, ".tif"))

  if (!is.null(save_path)) {
    writeRaster(cru_temp_stack, save_path, overwrite = TRUE)
    message("üíæ Saved raster to: ", save_path)
  }

  # 7. Optional: Plot a specified layer
  if (plot_layer %in% names(cru_temp_stack)) {
    plot(cru_temp_stack[[plot_layer]], main = paste("CRU Monthly Temperature -", plot_layer))
  } else {
    warning("‚ö†Ô∏è Layer '", plot_layer, "' not found in stack.")
  }

  return(cru_temp_stack)
}
```


```{r}
cru_stack <- stack_cru_temperature_from_sources(f)
```

```{r}
pg_grid = prio_blank_grid()

# Plot it (will show extent, grid cells)
plot(pg_grid, main = "Blank PRIO-GRID Raster")

```

```{r}
build_ym_table <- function(start_year, start_month, end_year, end_month) {
  years <- rep(start_year:end_year, each = 12)
  months <- rep(1:12, times = length(start_year:end_year))
  ym_df <- data.frame(year = years, month = months)
  ym_df <- ym_df[with(ym_df, year > start_year | (year == start_year & month >= start_month)), ]
  ym_df <- ym_df[with(ym_df, year < end_year | (year == end_year & month <= end_month)), ]
  ym_df$layer_name <- paste0("tmp_", sprintf("%04d_%02d", ym_df$year, ym_df$month))
  return(ym_df)
}

validate_date_range <- function(start_year, start_month, end_year, end_month, available_dates) {
  # Convert all dates to year-month format (first day of month)
  available_ym <- as.Date(format(available_dates, "%Y-%m-01"))
  first_date <- available_ym[1]
  last_date  <- available_ym[length(available_ym)]

  start_date <- as.Date(sprintf("%04d-%02d-01", start_year, start_month))
  end_date   <- as.Date(sprintf("%04d-%02d-01", end_year, end_month))

  if (start_date < first_date) {
    stop(sprintf("‚ùå Start date %s is before first raster date %s", format(start_date, "%Y-%m"), format(first_date, "%Y-%m")))
  }

  if (end_date > last_date) {
    stop(sprintf("‚ùå End date %s is after last raster date %s", format(end_date, "%Y-%m"), format(last_date, "%Y-%m")))
  }

  return(list(start_date = start_date, end_date = end_date))
}
```

```{r}
start_year = 2000
start_month = 01
end_year = 2000
end_month = 03

# Step 2: Validate date range is compatible with the raster
validate_date_range(start_year, start_month, end_year, end_month, time(cru_stack))
print(validate_date_range)

# Step 3: Build year-month table
ym_df <- build_ym_table(start_year, start_month, end_year, end_month)
print(ym_df)
```

```{r}
mask_cru_to_pg_stack <- function(cru_stack, pg_grid, ym_df = NULL) {
  library(terra)

  # Ensure alignment
  if (!compareGeom(cru_stack, pg_grid, stopOnError = FALSE)) {
    stop("Geometry mismatch: 'cru_stack' and 'pg_grid' must have identical extent, resolution, and CRS.")
  }


  # Get full layer info
  all_names <- names(cru_stack)
  all_dates <- time(cru_stack)

  full_ym_df <- data.frame(
    layer_name = all_names,
    year = as.integer(format(all_dates, "%Y")),
    month = as.integer(format(all_dates, "%m")),
    stringsAsFactors = FALSE
  )

  # Subset if ym_df is provided
  if (!is.null(ym_df)) {
    ym_df$layer_name <- paste0("tmp_", sprintf("%04d", ym_df$year), "_", sprintf("%02d", ym_df$month))
    full_ym_df <- merge(full_ym_df, ym_df, by = "layer_name")
    
    # Drop duplicate .y columns and keep only merged year/month
    full_ym_df$year <- full_ym_df$year.x
    full_ym_df$month <- full_ym_df$month.x
    full_ym_df <- full_ym_df[, c("layer_name", "year", "month")]
  }

  # Prepare output list
  masked_layers <- list()

  # Create mask once
  pg_mask <- !is.na(values(pg_grid))

  # Loop through selected layers
  for (i in seq_len(nrow(full_ym_df))) {
    lyr_name <- full_ym_df$layer_name[i]
    r <- cru_stack[[lyr_name]]
    r_masked <- mask(r, pg_grid)

    # Explicitly drop values outside PRIO-GRID
    vals <- values(r_masked)
    vals[!pg_mask] <- NA
    values(r_masked) <- vals

    names(r_masked) <- lyr_name
    masked_layers[[i]] <- r_masked
  }

  # Combine into stack
  masked_stack <- rast(masked_layers)

  # Preserve time if available
  if (!is.null(all_dates)) {
    matched_dates <- full_ym_df[match(names(masked_stack), full_ym_df$layer_name), ]
    time(masked_stack) <- as.Date(sprintf("%04d-%02d-16", matched_dates$year, matched_dates$month))
  }
  

  return(masked_stack)
}

```


```{r}
pg_stack <- mask_cru_to_pg_stack(cru_temp, pg_grid, ym_df)
```



```{r}
plot_pg_stack_to_pdf <- function(pg_stack, f, nrow = 3, ncol = 4) {
  library(terra)

  # Derive base output directory from f[1]
  base_dir <- dirname(f[1])
  report_dir <- file.path(base_dir, "reports")

  # Create 'reports' directory if it doesn't exist
  if (!dir.exists(report_dir)) {
    dir.create(report_dir, recursive = TRUE)
  }

  # Define final PDF path
  output_pdf <- file.path(report_dir, "CRU_pg_review.pdf")

  nlayers_total <- nlyr(pg_stack)
  layer_names <- names(pg_stack)

  # Calculate number of pages needed
  layers_per_page <- nrow * ncol
  n_pages <- ceiling(nlayers_total / layers_per_page)

  # Start PDF
  pdf(output_pdf, width = 11, height = 8.5)

  for (i in seq_len(n_pages)) {
    start_idx <- (i - 1) * layers_per_page + 1
    end_idx <- min(i * layers_per_page, nlayers_total)
    layer_subset <- pg_stack[[start_idx:end_idx]]

    par(mfrow = c(nrow, ncol), mar = c(2, 2, 2, 2))

    for (j in seq_len(nlyr(layer_subset))) {
      lyr <- layer_subset[[j]]
      plot(lyr, main = names(layer_subset)[j])
    }
  }

  dev.off()
  message("‚úÖ PDF saved to: ", output_pdf)
}


```


```{r}

plot_pg_stack_to_pdf(pg_stack, f)

```










# OLD -----
```{r}
cru_dir <- "/Users/gbenz/Documents/priogrid/CRU Climate/v4.09/d9ffee47-4e83-4805-9b3f-5e0e889fd2db"

cru_stack <- stack_cru_temperature_from_directory(
  nc_dir = cru_dir,
  save_path = "cru_monthly_1981_2024_stack.tif",  # Optional
  plot_layer = "tmp_2020_01"                     # Optional
)
```


```{r}
# Replace the path with your actual file path
file <- "/Users/gbenz/Documents/priogrid/data to ingest/cru_ts4.09.2011.2020.tmp.dat.nc"

# Load the NetCDF as a SpatRaster
temp <- rast(file)

# Check it has 120 layers (Jan 2011 to Dec 2020)
nlyr(temp)

# Extract time metadata from the SpatRaster
dates <- time(temp)

# Save first and last date
first_date <- dates[1]
last_date  <- dates[length(dates)]

# Confirm
print(first_date)
print(last_date)

temp
```



```{r}
# Step 1: Get all layer names
layer_names_all <- names(temp)

# Step 2: Identify the layers that belong to the 'tmp' variable
tmp_idx <- grep("^tmp", layer_names_all)

# Step 3: Extract only the 'tmp' layers
temp_only <- temp[[tmp_idx]]

# Step 4: Generate monthly timestamps (CRU mid-month convention)
dates <- seq(as.Date("2011-01-16"), as.Date("2020-12-16"), by = "month")

# Step 5: Attach the time stamps
time(temp_only) <- dates

# Step 6: Rename layers with readable format
names(temp_only) <- paste0("tmp_", format(dates, "%Y_%m"))

# Step 7: Confirm
print(temp_only)
temp_only
```


```{r}
# Extract by layer name
dec_2020 <- temp_only[["tmp_2020_12"]]

plot(dec_2020, main = "CRU Temperature - December 2020")
```


```{r}
# Load the CSV
pg_data <- read.csv("/Users/gbenz/Documents/Retrieve PG Data/recent_onemonth_raw_pgm_withgeom.csv")

# Convert to sf object using WKT geometry
pg_sf <- st_as_sf(pg_data, wkt = "geometry", crs = 4326)
```



```{r}

# Plot using ggplot2 with graticule lines (lat/lon)
ggplot(pg_sf) +
  geom_sf(fill = "lightblue", color = "black", size = 0.1) +
  coord_sf(crs = st_crs(4326), expand = FALSE) +
  theme_minimal() +
  labs(title = "PG Grid Cells with Lat/Lon Reference") +
  theme(panel.grid.major = element_line(color = "gray90"))

```


```{r}

# Ensure centroids are calculated and coordinates extracted
pg_centroids <- st_centroid(pg_sf)
coords <- st_coordinates(pg_centroids)
pg_sf$lon <- coords[, "X"]
pg_sf$lat <- coords[, "Y"]

# Subset 1: 0¬∞N to 5¬∞N and 20¬∞E to 25¬∞E
pg_subset_1 <- pg_sf %>%
  filter(lat >= 0, lat <= 5, lon >= 20, lon <= 25)

# Subset 2: 25¬∞N to 30¬∞N and 5¬∞W to 0¬∞E
pg_subset_2 <- pg_sf %>%
  filter(lat >= 25, lat <= 30, lon >= -5, lon <= 0)

# Subset 3: 30¬∞N to 35¬∞N and 50¬∞E to 55¬∞E
pg_subset_3 <- pg_sf %>%
  filter(lat >= 30, lat <= 35, lon >= 50, lon <= 55)

# Subset 4: 30¬∞S to 35¬∞S and 20¬∞E to 25¬∞E
pg_subset_4 <- pg_sf %>%
  filter(lat >= -35, lat <= -30, lon >= 20, lon <= 25)

```

```{r}
# Add an identifier to each subset
pg_subset_1$subset_id <- "Area 1: 0‚Äì5¬∞N, 20‚Äì25¬∞E"
pg_subset_2$subset_id <- "Area 2: 25‚Äì30¬∞N, 5¬∞W‚Äì0¬∞E"
pg_subset_3$subset_id <- "Area 3: 30‚Äì35¬∞N, 50‚Äì55¬∞E"
pg_subset_4$subset_id <- "Area 4: 30‚Äì35¬∞S, 20‚Äì25¬∞E"

# Combine into one sf object
pg_all_subsets <- bind_rows(pg_subset_1, pg_subset_2, pg_subset_3, pg_subset_4)

# Plot
ggplot() +
  # Base layer: full PG grid
  geom_sf(data = pg_sf, fill = "lightblue", color = "gray60", size = 0.1) +
  
  # Overlay subsets with color by subset_id
  geom_sf(data = pg_all_subsets, aes(color = subset_id), fill = NA, lwd = 0.7) +

  coord_sf(crs = st_crs(4326), expand = FALSE) +
  scale_color_manual(
    values = c("Area 1: 0‚Äì5¬∞N, 20‚Äì25¬∞E" = "red",
               "Area 2: 25‚Äì30¬∞N, 5¬∞W‚Äì0¬∞E" = "blue",
               "Area 3: 30‚Äì35¬∞N, 50‚Äì55¬∞E" = "green",
               "Area 4: 30‚Äì35¬∞S, 20‚Äì25¬∞E" = "purple")
  ) +
  theme_minimal() +
  labs(title = "Global PG Grid with Highlighted Subsets",
       color = "Subset Area") +
  theme(panel.grid.major = element_line(color = "gray90"))

```

```{r}
library(terra)
library(sf)

# Convert PG subset sf objects to SpatVector
subset_list <- list(
  Area1 = vect(pg_subset_1),
  Area2 = vect(pg_subset_2),
  Area3 = vect(pg_subset_3),
  Area4 = vect(pg_subset_4)
)

# Crop and mask raster to each subset area
masked_rasters <- lapply(subset_list, function(pg_area) {
  r_crop <- crop(dec_2020, pg_area)
  mask(r_crop, pg_area)
})

# Define reusable plotting function
plot_subset_rasters <- function() {
  par(mfrow = c(2, 2), mar = c(4, 4, 3, 2))  # 2x2 layout, with readable margins
  
  for (i in 1:4) {
    plot(masked_rasters[[i]], main = paste("Subset", names(subset_list)[i]))
    lines(subset_list[[i]], col = "white", lwd = 0.8)
  }
  
  par(mfrow = c(1, 1))  # reset layout
}

# 1. Display plot to screen
plot_subset_rasters()

# 2. Save same plot to PNG
png("/Users/gbenz/Documents/priogrid/pg_git/ClimateData_Notebooks/figures/cru_dec2020_subsets.png",
    width = 1200, height = 1000, res = 150)
plot_subset_rasters()
dev.off()


```


```{r}
library(terra)
library(sf)
library(dplyr)

# 1. Convert CRU raster to cell-centered points
raster_pts <- as.points(dec_2020)              # SpatVector of cell centers

# 2. Convert PRIO-GRID polygons to centroids
pg_centroids <- st_centroid(pg_sf)             # returns sf POINTS

# 3. Convert both to sf for spatial join and distance calculation
raster_pts_sf <- st_as_sf(raster_pts)          # from terra to sf
raster_pts_sf <- st_transform(raster_pts_sf, crs = st_crs(pg_centroids))  # ensure matching CRS

# 4. Match each PG centroid to its nearest raster cell center
nearest_match <- st_nearest_feature(pg_centroids, raster_pts_sf)

# 5. Calculate distance from PG centroid to raster point
distances <- st_distance(pg_centroids, raster_pts_sf[nearest_match, ], by_element = TRUE)

# 6. Summarize distances
cat("\n=== DISTANCE FROM PRIO-GRID CENTROIDS TO NEAREST RASTER CELL CENTER ===\n")
print(summary(distances))

# Optional: convert to numeric (in degrees or meters depending on CRS)
dist_deg <- as.numeric(distances)

cat(sprintf("Max offset: %.6f¬∞\n", max(dist_deg)))
cat(sprintf("Mean offset: %.6f¬∞\n", mean(dist_deg)))

# Optional: flag large offsets
if (max(dist_deg) < 1e-6) {
  cat("‚úÖ PASS: All PG centroids perfectly match raster centers (within floating point tolerance).\n")
} else {
  cat("‚ö†Ô∏è Some PG centroids may be offset from raster centers.\n")
}

```




```{r}
library(ggplot2)

# 1. Identify index of mismatched centroids
mismatch_idx <- which(distances >= tolerance_m)

# 2. Subset those PG polygons
pg_mismatched <- pg_sf[mismatch_idx, ]

# 3. Plot mismatched PG polygons in red
ggplot() +
  geom_sf(data = pg_sf, fill = "grey90", color = "grey60", size = 0.1) +  # full PG grid
  geom_sf(data = pg_mismatched, fill = "red", color = "black", size = 0.2) +
  coord_sf() +
  labs(
    title = "PRIO-GRID Cells with Centroid > 5m from Nearest Raster Cell Center",
    subtitle = paste("Count:", length(mismatch_idx))
  ) +
  theme_minimal()

ggsave(
  filename = "/Users/gbenz/Documents/priogrid/pg_git/ClimateData_Notebooks/figures/pg_mismatched_centroids.png",
  width = 10, height = 6, dpi = 300
)
```

```{r}

# 1. Convert raster to cell center points
raster_pts <- as.points(dec_2020)  # already masked to PG extent
raster_pts_sf <- st_as_sf(raster_pts)

# 2. Spatial join: which raster points fall in which PG cell
pg_sf$pg_id <- as.character(pg_sf$pg_id)  # ensure join-safe
raster_pts_join <- st_join(raster_pts_sf, pg_sf["pg_id"], join = st_within)

# 3. Count raster points per PG cell
raster_point_counts <- raster_pts_join |>
  st_drop_geometry() |>
  count(pg_id, name = "n_raster_pts")

# 4. Join back to PG polygons
pg_with_counts <- left_join(pg_sf, raster_point_counts, by = "pg_id")
pg_with_counts$n_raster_pts[is.na(pg_with_counts$n_raster_pts)] <- 0  # assign 0 where no raster point fell inside

# 5. Plot the number of raster cells per PG polygon
ggplot(pg_with_counts) +
  geom_sf(aes(fill = n_raster_pts), color = "grey50", size = 0.1) +
  scale_fill_viridis_c(option = "plasma", name = "# Raster Cells") +
  coord_sf() +
  labs(title = "Raster Cell Center Count per PRIO-GRID Cell") +
  theme_minimal()

ggsave(
  filename = "/Users/gbenz/Documents/priogrid/pg_git/ClimateData_Notebooks/figures/pg_zonal_rastercenter_count.png",
  width = 10, height = 6, dpi = 300)

```



#This begins the coding:

```{r}
# Define start and end year/month
start_year <- 2020
start_month <- 1
end_year <- 2020
end_month <- 3

# Save first and last date
first_date <- dates[1]
last_date  <- dates[length(dates)]

# Confirm
print(first_date)
print(last_date)

# Convert user-defined range to Date objects
start_date <- ymd(sprintf("%04d-%02d-01", start_year, start_month))
end_date   <- ymd(sprintf("%04d-%02d-01", end_year, end_month))

# Check if user range is within NetCDF range
if (start_date < first_date) {
  stop(sprintf("‚ùå ERROR: Start date %s is before the first available raster date (%s).", start_date, first_date))
}

if (end_date > last_date) {
  stop(sprintf("‚ùå ERROR: End date %s is after the last available raster date (%s).", end_date, last_date))
}

# Generate year-month combinations
years <- rep(start_year:end_year, each = 12)
months <- rep(1:12, times = length(start_year:end_year))

# Combine into data.frame
ym_df <- data.frame(year = years, month = months)

# Filter only months between start and end
ym_df <- ym_df[with(ym_df, year > start_year | (year == start_year & month >= start_month)), ]
ym_df <- ym_df[with(ym_df, year < end_year | (year == end_year & month <= end_month)), ]

# Create character values like "2024_01", "2024_02", etc.
ym_df$layer_name <- paste0("tmp_", sprintf("%04d_%02d", ym_df$year, ym_df$month))

# Confirm
head(ym_df)

```

```{r}
# 1. Get the first layer name
first_layer_name <- ym_df$layer_name[1]

# 2. Extract the raster layer from temp_only
r <- temp_only[[first_layer_name]]

# 3. Plot or inspect
plot(r, main = paste("CRU Temperature -", first_layer_name))

```


```{r}
library(terra)
library(dplyr)

# Convert PG polygons to SpatVector (terra format)
pg_terra <- vect(pg_sf)

# Initialize output data frame
climate_df <- data.frame()

# Loop over each row in ym_df
for (i in seq_len(nrow(ym_df))) {
  
  # Get layer info
  lyr_name <- ym_df$layer_name[i]
  year_val <- ym_df$year[i]
  month_val <- ym_df$month[i]
  
  # Skip if layer not found
  if (!(lyr_name %in% names(temp_only))) {
    warning("Missing raster layer:", lyr_name)
    next
  }
  
  # Extract the raster layer
  r <- temp_only[[lyr_name]]
  
  # Zonal mean extraction (area-based)
  extracted <- extract(r, pg_terra, fun = mean, na.rm = TRUE)
  
  # Build tidy result for this month
  df <- data.frame(
    pg_id = pg_sf$pg_id,
    year = year_val,
    month = month_val,
    tmp_value = extracted[[2]]  # mean values
  )
  
  # Append
  climate_df <- bind_rows(climate_df, df)
}

# Preview result
head(climate_df)


```

