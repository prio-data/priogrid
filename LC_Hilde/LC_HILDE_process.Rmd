
```{r}
#install.packages("terra") # For raster and NetCDF handling
library(terra)
library(sf)
library(dplyr)
library(ggplot2)
library(lubridate)
```


```{r}
#' Reads the CRU data
#'
#'
#'
#' @return an object of class sf
#' @export
#'
#' @references
#' \insertRef{winklerHILDAGlobalLand2020}{priogrid}
read_hilde <- function() {
f <- get_pgfile(source_name = "HILDE",
source_version = "v1.0",
id = "82bc4c6f-9904-484f-aa9a-77771d076690")
return(f)
}


```

```{r}
f <- read_hilde()
```

```{r}
print(f)
```


```{r}
zip_file <- function(f) {
  # Load necessary package
  library(tools)

  # Validate the zip file path
  if (!file.exists(f)) {
    stop("File not found: ", f)
  }

  # Build unzipped folder name
  zip_name <- basename(f)  # "hildap_vGLOB-1.0_geotiff.zip"
  base_name <- file_path_sans_ext(zip_name)  # "hildap_vGLOB-1.0_geotiff"
  target_dir <- file.path(dirname(f), paste0(base_name, "_unzipped"))

  # Create the directory
  dir.create(target_dir, showWarnings = FALSE, recursive = TRUE)

  # Unzip contents
  message("Unzipping to: ", target_dir)
  unzip(f, exdir = target_dir)

  return(target_dir)
}

```

```{r}
unzipped_directory <- zip_file(f) 
```

```{r}
# List all files (with full paths) in the unzipped directory
unzipped_files <- list.files(unzipped_directory, full.names = TRUE)
print(unzipped_files)
```

```{r}
# Define the target subdirectory
states_dir <- file.path(unzipped_directory, "hildap_vGLOB-1.0_geotiff_wgs84", "hildap_GLOB-v1.0_lulc-states")

# List all files in that directory (non-recursive since you’re targeting a specific folder)
state_files <- list.files(states_dir, full.names = TRUE)
print(state_files)
```

```{r}
filter_files_by_year <- function(file_paths, start_year, end_year) {
  # Extract 4-digit year from each file name
  years <- as.numeric(sub(".*?(\\d{4}).*", "\\1", basename(file_paths)))

  # Filter files based on year range
  keep <- years >= start_year & years <= end_year
  return(file_paths[keep])
}

```

```{r}
# Define your year range
start_year <- 2000
end_year <- 2010

# Assume this is the full list of .tif files
tif_files <- list.files(states_dir, pattern = "\\.tif$", full.names = TRUE)

# Filter the list
filtered_files <- filter_files_by_year(tif_files, start_year, end_year)

print(filtered_files)

```

```{r}
library(terra)

# Load the first file from filtered_files
r <- rast(filtered_files[1])

# Plot the raster
plot(r, main = basename(filtered_files[1]))

```

```{r}
pg_grid = prio_blank_grid()
# Plot it (will show extent, grid cells)
plot(pg_grid, main = "Blank PRIO-GRID Raster")
```

```{r}
# Convert PRIO-GRID to polygons
pg_grid <- prio_blank_grid()
pg_grid[] <- as.integer(round(pg_grid[]))
names(pg_grid) <- "pg_id"
pg_vect <- as.polygons(pg_grid, na.rm = TRUE)
names(pg_vect) <- "pg_id"

```


```{r}
pg_grid
```
```{r}
get_valid_tile_sizes <- function(pg_grid, increment = 10) {
  e <- ext(pg_grid)
  
  x_extent <- e[2] - e[1]  # xmax - xmin
  y_extent <- e[4] - e[3]  # ymax - ymin

  max_size <- min(x_extent, y_extent)
  candidates <- seq(increment, max_size, by = increment)
  
  valid_sizes <- candidates[
    (x_extent %% candidates) == 0 & (y_extent %% candidates) == 0
  ]
  
  return(valid_sizes)
}

generate_tiles_checked <- function(pg_grid, tile_size, increment = 10) {
  # Step 1: Get valid sizes based on pg_grid extent
  valid_sizes <- get_valid_tile_sizes(pg_grid, increment = increment)
  
  # Step 2: Validate user input
  if (!(tile_size %in% valid_sizes)) {
    stop(sprintf(
      "Invalid tile size: %d°. It does not divide evenly into the PRIO-GRID extent.\n Valid options: %s",
      tile_size,
      paste(valid_sizes, collapse = ", ")
    ))
  }

  # Step 3: Extract extent and generate tile boundaries
  e <- ext(pg_grid)
  xmin <- floor(e[1])
  xmax <- ceiling(e[2])
  ymin <- floor(e[3])
  ymax <- ceiling(e[4])
  
  lon_seq <- seq(xmin, xmax - tile_size, by = tile_size)
  lat_seq <- seq(ymin, ymax - tile_size, by = tile_size)
  
  grid <- expand.grid(lon = lon_seq, lat = lat_seq)
  tile_df <- data.frame(
    tile_id = seq_len(nrow(grid)),
    xmin = grid$lon,
    xmax = grid$lon + tile_size,
    ymin = grid$lat,
    ymax = grid$lat + tile_size
  )
  
  return(tile_df)
}


```


```{r}
valid_sizes <- get_valid_tile_sizes(pg_grid)
print(valid_sizes)
```


```{r}
tile_df <- generate_tiles_checked(pg_grid, tile_size = 30)
print(tile_df)

```





```{r}
# Step : Convert each extent to a SpatVector polygon
tile_polys <- lapply(1:nrow(tile_df), function(i) {
  e <- ext(tile_df$xmin[i], tile_df$xmax[i], tile_df$ymin[i], tile_df$ymax[i])
  p <- as.polygons(e)
  crs(p) <- "EPSG:4326"
  return(p)
})

# Step 4: Combine all polygons into one SpatVector
tile_vector <- do.call(rbind, tile_polys)

# Step 5: Plot the tile grid
# Plot the PRIO-GRID raster
plot(pg_grid, main = "PRIO-GRID with 20°x20° Tiles")

# Overlay the tile grid as borders
lines(tile_vector, col = "red", lwd = 2)

```

```{r}
#Select just 1 tile to process for tests:
first_file <- filtered_files[1]
first_file
```


```{r}
process_landcover_in_tiles <- function(tif_path, pg_vect, tile_df) {
  r <- rast(tif_path)
  year <- as.numeric(sub(".*?(\\d{4}).*", "\\1", basename(tif_path)))
  pixel_area_km2 <- prod(res(r)) / 1e6
  
  results <- list()
  total_start <- Sys.time()  # Start global timer
  
  for (i in seq_len(nrow(tile_df))) {
    tile_start <- Sys.time()  # Start tile timer
    
    # Report which tile is being processed
    tile_info <- tile_df[i, ]
    message(sprintf("Processing tile %d of %d: [%d°, %d°, %d°, %d°]",
                    i, nrow(tile_df),
                    tile_info$xmin, tile_info$xmax,
                    tile_info$ymin, tile_info$ymax))
    
    # Create extent and crop
    bbox <- ext(tile_info$xmin, tile_info$xmax, tile_info$ymin, tile_info$ymax)
    r_tile <- crop(r, bbox)
    
    if (nlyr(r_tile) == 0) {
      message(sprintf("Skipping tile %d (no data)", i))
      next
    }
    
    # Extract values from full PRIO-GRID
    extract_df <- terra::extract(r_tile, pg_vect, fun = table, cells = FALSE)
    extract_df <- as.data.frame(extract_df)
    names(extract_df)[1] <- "pg_id"
    
    long_df <- extract_df %>%
      tidyr::pivot_longer(cols = -pg_id, names_to = "landcover_type", values_to = "count") %>%
      filter(!is.na(count)) %>%
      mutate(
        landcover_type = as.integer(gsub("lyr.1.", "", landcover_type, fixed = TRUE)),
        year = year,
        area_km2 = count * pixel_area_km2
      )
    
    results[[i]] <- long_df
    
    tile_time <- difftime(Sys.time(), tile_start, units = "mins")
    message(sprintf("Finished tile %d in %.2f minutes", i, tile_time))
  }
  
  # Combine and summarize
  combined_df <- bind_rows(results) %>%
    group_by(pg_id, landcover_type, year) %>%
    summarize(area_km2 = sum(area_km2), .groups = "drop")
  
  total_time <- difftime(Sys.time(), total_start, units = "mins")
  message(sprintf("Finished all tiles for year %d in %.2f minutes", year, total_time))
  
  return(combined_df)
}

```

```{r}
tile_df
```


```{r}
lc_output <- process_landcover_in_tiles(first_file, pg_vect, tile_df) 

```

